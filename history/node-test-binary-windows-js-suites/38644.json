{"failedTests":[{"testName":"wpt/test-user-timing","timestamp":1770281918583,"status":"FAILED","jobName":"node-test-binary-windows-js-suites","config":"node-test-binary-windows-js-suites Â» 1,win11-arm64-COMPILED_BY-vs2022_clang-arm64 #38644","buildUrl":"https://ci.nodejs.org/job/node-test-binary-windows-js-suites/RUN_SUBSET=1,nodes=win11-arm64-COMPILED_BY-vs2022_clang-arm64/38644/","buildNumber":38644,"builtOn":"test-azure_msft-win11_vs2022-arm64-3","nodeVersion":"24.13.1","commitHash":"065c9b06b5ca0d057eca02c664d070d5614a6e61","callStack":[{"upstreamBuild":75014,"upstreamProject":"node-test-commit-windows-fanned","upstreamUrl":"job/node-test-commit-windows-fanned/"},{"upstreamBuild":85286,"upstreamProject":"node-test-commit","upstreamUrl":"job/node-test-commit/"},{"upstreamBuild":104,"upstreamProject":"node-daily-v24.x-staging","upstreamUrl":"job/node-daily-v24.x-staging/"}],"tap":{"ok":false,"name":"wpt/test-user-timing","id":1203,"buffered":false,"tapError":null,"skip":false,"todo":": Fix flaky test","previous":null,"plan":null,"diag":{"severity":"flaky","exitcode":1,"stack":"[SKIPPED] idlharness-shadowrealm.window.js: ShadowRealm support is not enabled\n[SKIPPED] invoke_with_timing_attributes.worker.js: importScripts not supported\n[SKIPPED] performance-measure-invalid.worker.js: importScripts not supported\n[PASS] PerformanceObserver with buffered flag sees previous marks\n[PASS] PerformanceObserver with buffered flag sees previous measures\n[PASS] Clearing all marks remove all of them.\n[PASS] Clearing all marks remove all of them.\n[PASS] getEntriesByType values are case sensitive\n[PASS] Clearing a non-existent mark doesn't affect existing marks\n[PASS] Clearing a non-existent measure doesn't affect existing measures\n[PASS] Clearing an existent mark doesn't affect other existing marks\n[PASS] Clearing an existent measure doesn't affect other existing measures\n[PASS] Validate the user timing entry type PerformanceMark\n[PASS] Validate the user timing entry type PerformanceMeasure\n[PASS] Mark entry can be created by 'new PerformanceMark(string)'.\n[PASS] Mark entry can be created by 'new PerformanceMark(string, {})'.\n[PASS] Mark entry can be created by 'new PerformanceMark(string, {startTime})'.\n[PASS] Mark entry can be created by 'new PerformanceMark(string, {detail})'.\n[PASS] Mark entry can be created by 'new PerformanceMark(string, {startTime, detail})'.\n[PASS] Using new PerformanceMark() shouldn't add the entry to performance timeline.\n[PASS] [performance.mark]: Number should be rejected as the mark-options.\n[PASS] [new PerformanceMark]: Number should be rejected as the mark-options.\n[PASS] [performance.mark]: NaN should be rejected as the mark-options.\n[PASS] [new PerformanceMark]: NaN should be rejected as the mark-options.\n[PASS] [performance.mark]: Infinity should be rejected as the mark-options.\n[PASS] [new PerformanceMark]: Infinity should be rejected as the mark-options.\n[PASS] [performance.mark]: String should be rejected as the mark-options.\n[PASS] [new PerformanceMark]: String should be rejected as the mark-options.\n[PASS] [performance.mark]: Negative startTime in mark-options should be rejected\n[PASS] [new PerformanceMark]: Negative startTime in mark-options should be rejected\n[PASS] L3: performance.measure(name) should return an entry.\n[PASS] mark entries' detail and startTime are customizable.\n[PASS] L3: performance.measure(name, param1) should return an entry.\n[PASS] L3: performance.measure(name, param1, param2) should return an entry.\n[PASS] L3: performance.mark(name) should return an entry.\n[PASS] L3: performance.mark(name, param) should return an entry.\n[PASS] When the end mark is given and the start is unprovided, the end time of the measure entry should be the end mark's time, the start time should be 0.\n[PASS] When the start mark is given and the end is unprovided, the start time of the measure entry should be the start mark's time, the end should be now.\n[PASS] When start and end mark are both given, the start time and end time of the measure entry should be the the marks' time, repectively\n[PASS] Entry 0 is properly created\n[PASS] Entry 1 is properly created\n[PASS] Entry 0 has the proper name\n[PASS] idl_test validation\n[UNEXPECTED_FAILURE][FAIL] Entry 0 startTime is approximately correct (up to 20ms difference allowed)\nassert_approx_equals: expected 917.4353 +/- 20 but got 897.2347\n    at Test.<anonymous> (d:\\workspace\\node-test-binary-windows-js-suites\\node\\test\\fixtures\\wpt\\user-timing\\mark.any.js:61:8)\n    at Test.step (d:\\workspace\\node-test-binary-windows-js-suites\\node\\test\\fixtures\\wpt\\resources\\testharness.js:2869:25)\n    at test (d:\\workspace\\node-test-binary-windows-js-suites\\node\\test\\fixtures\\wpt\\resources\\testharness.js:633:30)\n    at test_mark (d:\\workspace\\node-test-binary-windows-js-suites\\node\\test\\fixtures\\wpt\\user-timing\\mark.any.js:59:4)\n    at d:\\workspace\\node-test-binary-windows-js-suites\\node\\test\\fixtures\\wpt\\user-timing\\mark.any.js:117:3\nCommand: d:\\workspace\\node-test-binary-windows-js-suites\\node\\Release\\node.exe  d:\\workspace\\node-test-binary-windows-js-suites\\node\\test\\wpt\\test-user-timing.js 'mark.any.js'\n\n[PASS] Entry 0 has the proper entryType\n[PASS] Entry 0 duration == 0\n[PASS] getEntriesByName(\"mark\", \"mark\")[0] returns an object containing a \"mark\" mark\n[PASS] The mark returned by getEntriesByName(\"mark\", \"mark\")[0] matches the mark returned by getEntriesByName(\"mark\")[0]\n[PASS] getEntries()[0] returns an object containing a \"mark\" mark\n[PASS] The mark returned by getEntries()[0] matches the mark returned by getEntriesByName(\"mark\")[0]\n[PASS] getEntriesByType(\"mark\")[0] returns an object containing a \"mark\" mark\n[PASS] The mark returned by getEntriesByType(\"mark\")[0] matches the mark returned by getEntriesByName(\"mark\")[0]\n[PASS] Entry 1 has the proper name\n[PASS] Entry 1 startTime is approximately correct (up to 20ms difference allowed)\n[PASS] Entry 1 has the proper entryType\n[PASS] Entry 1 duration == 0\n[PASS] getEntriesByName(\"mark\", \"mark\")[1] returns an object containing a \"mark\" mark\n[PASS] The mark returned by getEntriesByName(\"mark\", \"mark\")[1] matches the mark returned by getEntriesByName(\"mark\")[1]\n[PASS] getEntries()[1] returns an object containing a \"mark\" mark\n[PASS] The detail property in the mark constructor should be structured-clone.\n[PASS] The detail property in the mark method should be structured-clone.\n[PASS] When accessing detail from a mark entry and the detail is not provided, just return a null value.\n[PASS] Mark: Throw an exception when the detail property cannot be structured-serialized.\n[PASS] Partial interface Performance: original interface defined\n[PASS] Partial interface Performance: member names are unique\n[PASS] PerformanceMark interface: existence and properties of interface object\n[PASS] PerformanceMark interface object length\n[PASS] PerformanceMark interface object name\n[PASS] PerformanceMark interface: existence and properties of interface prototype object\n[PASS] PerformanceMark interface: existence and properties of interface prototype object's \"constructor\" property\n[PASS] PerformanceMark interface: existence and properties of interface prototype object's @@unscopables property\n[PASS] The mark returned by getEntries()[1] matches the mark returned by getEntriesByName(\"mark\")[1]\n[PASS] getEntriesByType(\"mark\")[1] returns an object containing a \"mark\" mark\n[PASS] The mark returned by getEntriesByType(\"mark\")[1] matches the mark returned by getEntriesByName(\"mark\")[1]\n[PASS] Create a mark \"existing_mark\"\n[PASS] self.performance.measure(\"measure\", \"mark\"), where \"mark\" is a non-existent mark, throws a SyntaxError exception.\n[PASS] self.performance.measure(\"measure\", \"mark\", \"existing_mark\"), where \"mark\" is a non-existent mark, throws a SyntaxError exception.\n[PASS] self.performance.measure(\"measure\", \"existing_mark\", \"mark\"), where \"mark\" is a non-existent mark, throws a SyntaxError exception.\n[PASS] measure should throw a TypeError when passed an invalid argument combination\n[PASS] The detail property in the measure method should be structured-clone.\n[PASS] The detail property in the measure method should be the same reference.\n[PASS] When accessing detail from a measure entry and the detail is not provided, just return a null value.\n[PASS] Measure: Throw an exception when the detail property cannot be structured-serialized.\n[PASS] The detail object is cloned when passed to mark API.\n[PASS] PerformanceMark must be primary interface of mark\n[PASS] Stringification of mark\n[PASS] PerformanceMark interface: mark must inherit property \"detail\" with the proper type\n[PASS] measure entries' detail and start/end are customizable\n[PASS] self.performance.measure(\"measure\", \"mark\", \"mark\"), where \"mark\" is a non-existent mark, throws a SyntaxError exception.\n[PASS] PerformanceMeasure interface: existence and properties of interface object\n[PASS] PerformanceMeasure interface object length\n[PASS] PerformanceMeasure interface object name\n[PASS] PerformanceMeasure interface: existence and properties of interface prototype object\n[PASS] PerformanceMeasure interface: existence and properties of interface prototype object's \"constructor\" property\n[PASS] PerformanceMeasure interface: existence and properties of interface prototype object's @@unscopables property\n[PASS] PerformanceMeasure must be primary interface of measure\n[PASS] Stringification of measure\n[PASS] PerformanceMeasure interface: measure must inherit property \"detail\" with the proper type\n[PASS] Performance interface: operation mark(DOMString, optional PerformanceMarkOptions)\n[PASS] Performance interface: operation clearMarks(optional DOMString)\n[PASS] Performance interface: operation measure(DOMString, optional (DOMString or PerformanceMeasureOptions), optional DOMString)\n[PASS] Performance interface: operation clearMeasures(optional DOMString)\n[PASS] Performance interface: performance must inherit property \"mark(DOMString, optional PerformanceMarkOptions)\" with the proper type\n[PASS] Performance interface: calling mark(DOMString, optional PerformanceMarkOptions) on performance with too few arguments must throw TypeError\n[PASS] Performance interface: performance must inherit property \"clearMarks(optional DOMString)\" with the proper type\n[PASS] Performance interface: calling clearMarks(optional DOMString) on performance with too few arguments must throw TypeError\n[PASS] Performance interface: performance must inherit property \"measure(DOMString, optional (DOMString or PerformanceMeasureOptions), optional DOMString)\" with the proper type\n[PASS] Performance interface: calling measure(DOMString, optional (DOMString or PerformanceMeasureOptions), optional DOMString) on performance with too few arguments must throw TypeError\n[PASS] Performance interface: performance must inherit property \"clearMeasures(optional DOMString)\" with the proper type\n[PASS] Performance interface: calling clearMeasures(optional DOMString) on performance with too few arguments must throw TypeError\n[PASS] PerformanceMark interface: attribute detail\n[PASS] PerformanceMeasure interface: attribute detail\n[PASS] idl_test setup\n[PASS] supportedEntryTypes contains 'mark' and 'measure'.\n[PASS] 'mark' entries should be observable.\n[PASS] 'measure' entries should be observable.\n[PASS] self.performance.mark is defined.\n[PASS] self.performance.clearMarks is defined.\n[PASS] self.performance.measure is defined.\n[PASS] self.performance.clearMeasures is defined.\n\n{\n  \"idlharness-shadowrealm.window.js\": {\n    \"skip\": \"ShadowRealm support is not enabled\"\n  },\n  \"invoke_with_timing_attributes.worker.js\": {\n    \"skip\": \"importScripts not supported\"\n  },\n  \"mark.any.js\": {\n    \"fail\": {\n      \"unexpected\": [\n        \"Entry 0 startTime is approximately correct (up to 20ms difference allowed)\"\n      ]\n    }\n  },\n  \"performance-measure-invalid.worker.js\": {\n    \"skip\": \"importScripts not supported\"\n  }\n}\n\nRan 21/24 tests, 3 skipped, 20 passed, 0 expected failures, 1 unexpected failures, 0 unexpected passes\nd:\\workspace\\node-test-binary-windows-js-suites\\node\\test\\common\\wpt.js:802\n        throw new Error(\n        ^\n\nError: Found 1 unexpected failures. Consider updating test\\wpt\\status\\user-timing.json for these files:\nmark.any.js\n    at process.<anonymous> (d:\\workspace\\node-test-binary-windows-js-suites\\node\\test\\common\\wpt.js:802:15)\n    at process.emit (node:events:508:28)\n\nNode.js v24.13.1-pre"},"time":1290.208,"fullname":"wpt/test-user-timing","closingTestPoint":false}}]}